{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad9e8d4",
   "metadata": {},
   "source": [
    "# Topic Modeling with Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a68602d",
   "metadata": {},
   "source": [
    "## Implementation attemps\n",
    "\n",
    "**Reference:** https://towardsdatascience.com/topic-modeling-with-bert-779f7db187e6\n",
    "\n",
    "**Requierements:** py -3.8 -m pip install umap-learn hdbscan sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6686c8f",
   "metadata": {},
   "source": [
    "## using Our own train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a70a437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>message</th>\n",
       "      <th>link</th>\n",
       "      <th>domain</th>\n",
       "      <th>rating</th>\n",
       "      <th>orientation</th>\n",
       "      <th>sourceEchochamber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-27 16:21:29</td>\n",
       "      <td>The balls on this guy, huh?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.tmz.com/2020/10/27/arizona-racist-...</td>\n",
       "      <td>tmz.com</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-20 14:34:31</td>\n",
       "      <td>Lindell has come under fire for promoting pote...</td>\n",
       "      <td>En Serio?</td>\n",
       "      <td>https://www.forbes.com/sites/andrewsolender/20...</td>\n",
       "      <td>forbes.com</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-17 15:35:49</td>\n",
       "      <td>Biden has told aides that he's concerned that ...</td>\n",
       "      <td>Wary ?? Wary ?? More like he is worried that t...</td>\n",
       "      <td>https://www.msn.com/en-us/news/politics/presid...</td>\n",
       "      <td>msn.com</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-03 03:19:18</td>\n",
       "      <td>The response was a remarkable moment at a pivo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.nbcnews.com/politics/elections/sup...</td>\n",
       "      <td>nbcnews.com</td>\n",
       "      <td>T</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-30 16:26:09</td>\n",
       "      <td>Astronaut Jeanette Epps is the first Black wom...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://newsone.com/4005134/nasa-astronaut-jea...</td>\n",
       "      <td>newsone.com</td>\n",
       "      <td>T</td>\n",
       "      <td>Slightly Left</td>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                           headline  \\\n",
       "0  2020-10-27 16:21:29                        The balls on this guy, huh?   \n",
       "1  2020-08-20 14:34:31  Lindell has come under fire for promoting pote...   \n",
       "2  2020-11-17 15:35:49  Biden has told aides that he's concerned that ...   \n",
       "3  2021-03-03 03:19:18  The response was a remarkable moment at a pivo...   \n",
       "4  2020-08-30 16:26:09  Astronaut Jeanette Epps is the first Black wom...   \n",
       "\n",
       "                                             message  \\\n",
       "0                                                NaN   \n",
       "1                                          En Serio?   \n",
       "2  Wary ?? Wary ?? More like he is worried that t...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                link       domain rating  \\\n",
       "0  https://www.tmz.com/2020/10/27/arizona-racist-...      tmz.com      N   \n",
       "1  https://www.forbes.com/sites/andrewsolender/20...   forbes.com      T   \n",
       "2  https://www.msn.com/en-us/news/politics/presid...      msn.com      T   \n",
       "3  https://www.nbcnews.com/politics/elections/sup...  nbcnews.com      T   \n",
       "4  https://newsone.com/4005134/nasa-astronaut-jea...  newsone.com      T   \n",
       "\n",
       "     orientation sourceEchochamber  \n",
       "0            NaN           Liberal  \n",
       "1            NaN           Liberal  \n",
       "2            NaN      Conservative  \n",
       "3            NaN           Liberal  \n",
       "4  Slightly Left           Liberal  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df=pd.read_csv('data/TCCSocialMediaData_train.csv')\n",
    "df=df.drop(['Unnamed: 0','Unnamed: 0.1'], axis=1)\n",
    "df=df[df['headline'].notna()]\n",
    "#If we were to take only half\n",
    "#df = shuffle(df)\n",
    "#df=df[0:int(len(df)/2)]\n",
    "\n",
    "df=df.reset_index(drop=True)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38d1d4c",
   "metadata": {},
   "source": [
    "## Same but using Bert Large\n",
    "\n",
    "- Complete library on hugging face hub: https://huggingface.co/sentence-transformers\n",
    "- Bert large for sentence modeling: https://huggingface.co/sentence-transformers/bert-large-nli-mean-tokens\n",
    "- encoding time +/-40 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931860ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "model = SentenceTransformer('bert-large-nli-mean-tokens')\n",
    "\n",
    "data=df[df['headline'].notna()]['headline'].tolist()\n",
    "print(len(data))\n",
    "embeddings = model.encode(data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81aab2",
   "metadata": {},
   "source": [
    "### Dimension Reduction with UMAP\n",
    "\n",
    "Reduce the dimensionality to 5 while keeping the size of the local neighborhood at 15. You can play around with these values to optimize for your topic creation. Note that a too low dimensionality results in a loss of information while a too high dimensionality results in poorer clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6899eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap_embeddings = umap.UMAP(n_neighbors=5, \n",
    "                            n_components=50, \n",
    "                            metric='cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aeaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(umap_embeddings))\n",
    "print(umap_embeddings[0])\n",
    "len(umap_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d6b73",
   "metadata": {},
   "source": [
    "### Cluster the documents with HDBSCAN\n",
    "\n",
    "Cluster the documents with HDBSCAN. HDBSCAN is a density-based algorithm that works quite well with UMAP since UMAP maintains a lot of local structure even in lower-dimensional space. Moreover, HDBSCAN does not force data points to clusters as it considers them outliers\n",
    "\n",
    "https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f839d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=50,\n",
    "                          metric='euclidean',                      \n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb30893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Prepare data\n",
    "umap_data = umap.UMAP(n_neighbors=5, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "result = pd.DataFrame(umap_data, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_\n",
    "\n",
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "outliers = result.loc[result.labels == -1, :]\n",
    "clustered = result.loc[result.labels != -1, :]\n",
    "plt.scatter(outliers.x, outliers.y, color='#BDBDBD', s=0.05)\n",
    "plt.scatter(clustered.x, clustered.y, c=clustered.labels, s=0.05, cmap='hsv_r')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0911b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('cluster_5_15_15.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fd3b96",
   "metadata": {},
   "source": [
    "### Topic Creation with TFIDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8195fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baed6327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>The balls on this guy, huh? Lindell has come u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ZeroHedge - On a long enough timeline, the sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>PolitiFact is a fact-checking website that rat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>üò≥ üòê üåäü§úüèªüö™üó≥ üò® üò°ü§¨ü§¨ü§¨ üò≥üò≥üò≥ ü¶†üïµüèª‚Äç‚ôÇÔ∏è\\n\\n üëÄüëÄ üòØü§Ø ü§î... \\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Wow... Wow... Wow... Wow... Wow... Just wow......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>503</td>\n",
       "      <td>There's no single domestic terrorism statute, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>504</td>\n",
       "      <td>A narrow victory for either side does not fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>505</td>\n",
       "      <td>In America, the two political parties don‚Äôt co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>506</td>\n",
       "      <td>Get them out of there! Confirmed! Stand Down o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>507</td>\n",
       "      <td>'He had nothing to do with it' ‚ÄúWhat I cannot ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic                                                Doc\n",
       "0       -1  The balls on this guy, huh? Lindell has come u...\n",
       "1        0  ZeroHedge - On a long enough timeline, the sur...\n",
       "2        1  PolitiFact is a fact-checking website that rat...\n",
       "3        2  üò≥ üòê üåäü§úüèªüö™üó≥ üò® üò°ü§¨ü§¨ü§¨ üò≥üò≥üò≥ ü¶†üïµüèª‚Äç‚ôÇÔ∏è\\n\\n üëÄüëÄ üòØü§Ø ü§î... \\n\\...\n",
       "4        3  Wow... Wow... Wow... Wow... Wow... Just wow......\n",
       "..     ...                                                ...\n",
       "504    503  There's no single domestic terrorism statute, ...\n",
       "505    504  A narrow victory for either side does not fund...\n",
       "506    505  In America, the two political parties don‚Äôt co...\n",
       "507    506  Get them out of there! Confirmed! Stand Down o...\n",
       "508    507  'He had nothing to do with it' ‚ÄúWhat I cannot ...\n",
       "\n",
       "[509 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df = pd.DataFrame(data, columns=[\"Doc\"])\n",
    "docs_df['Topic'] = cluster.labels_\n",
    "docs_df['Doc_ID'] = range(len(docs_df))\n",
    "docs_df.to_csv('docs_df.csv')\n",
    "docs_per_topic = docs_df.groupby(['Topic'], as_index = False).agg({'Doc': ' '.join})\n",
    "docs_per_topic.to_csv('docs_per_topic.csv')\n",
    "docs_per_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e14a03b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n",
      "508\n",
      "503\n"
     ]
    }
   ],
   "source": [
    "print(len(docs_per_topic))\n",
    "docs_per_topic=docs_per_topic[docs_per_topic['Topic']!=0]\n",
    "docs_per_topic=docs_per_topic.reset_index(drop=True)\n",
    "print(len(docs_per_topic))\n",
    "docs_per_topic=docs_per_topic[docs_per_topic['Doc'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
    "print(len(docs_per_topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae5aa7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    t = count.transform(documents).toarray()\n",
    "    \n",
    "    w = t.sum(axis=1)\n",
    "\n",
    "    tf = np.divide(t.T, w)\n",
    "    sum_t = t.sum(axis=0)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count\n",
    "  \n",
    "tf_idf, count = c_tf_idf(docs_per_topic.Doc.values, m=len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ef626",
   "metadata": {},
   "source": [
    "### Topic Representation\n",
    "In order to create a topic representation, we take the top 20 words per topic based on their c-TF-IDF scores. The higher the score, the more representative it should be of its topic as the score is a proxy of information density.\n",
    "\n",
    "The topic name-1 refers to all documents that did not have any topics assigned. The great thing about HDBSCAN is that not all documents are forced towards a certain cluster. If no cluster could be found, then it is simply an outlier.\n",
    "\n",
    "We can see that topics 7, 43, 12, and 41 are the largest clusters that we could create. To view the words belonging to those topics, we can simply use the dictionarytop_n_words to access these topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3069a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>347704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>361</td>\n",
       "      <td>4247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>457</td>\n",
       "      <td>3446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>138</td>\n",
       "      <td>3154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>169</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>174</td>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>385</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>382</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>502</td>\n",
       "      <td>1618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic    Size\n",
       "0       -1  347704\n",
       "362    361    4247\n",
       "458    457    3446\n",
       "139    138    3154\n",
       "170    169    2338\n",
       "175    174    2106\n",
       "12      11    2053\n",
       "386    385    1980\n",
       "383    382    1900\n",
       "503    502    1618"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n):\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.Topic)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['Topic'])\n",
    "                     .Doc\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"Topic\": \"Topic\", \"Doc\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes\n",
    "\n",
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(docs_df)\n",
    "topic_sizes.to_csv('topic_sizes.csv')\n",
    "topic_sizes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f68efdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>319</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>359</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>290</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>154</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>503</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>169</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>138</td>\n",
       "      <td>3154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>457</td>\n",
       "      <td>3446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>361</td>\n",
       "      <td>4247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>347704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic    Size\n",
       "320    319      50\n",
       "360    359      51\n",
       "291    290      51\n",
       "155    154      51\n",
       "504    503      51\n",
       "..     ...     ...\n",
       "170    169    2338\n",
       "139    138    3154\n",
       "458    457    3446\n",
       "362    361    4247\n",
       "0       -1  347704\n",
       "\n",
       "[509 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sizes.sort_values(['Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24843650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Size</th>\n",
       "      <th>topic top words</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>347704</td>\n",
       "      <td>[(trump, 0.021263067193352816), (president, 0....</td>\n",
       "      <td>[trump, president, biden, election, said, joe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>361</td>\n",
       "      <td>4247</td>\n",
       "      <td>[(twitter, 0.09277363693910848), (facebook, 0....</td>\n",
       "      <td>[twitter, facebook, social, media, account, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>457</td>\n",
       "      <td>3446</td>\n",
       "      <td>[(good, 0.07022461672120524), (great, 0.042902...</td>\n",
       "      <td>[good, great, right, think, know, time, love, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>138</td>\n",
       "      <td>3154</td>\n",
       "      <td>[(https, 0.1580439995285021), (com, 0.15198126...</td>\n",
       "      <td>[https, com, www, fbclid, 2020, msn, politics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>169</td>\n",
       "      <td>2338</td>\n",
       "      <td>[(russian, 0.10859609065953478), (russia, 0.09...</td>\n",
       "      <td>[russian, russia, intelligence, putin, vladimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>120</td>\n",
       "      <td>51</td>\n",
       "      <td>[(game, 0.2633899598384372), (star, 0.24340667...</td>\n",
       "      <td>[game, star, baseball, league, atlanta, major,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>151</td>\n",
       "      <td>51</td>\n",
       "      <td>[(democratic, 0.12098058076373801), (joe, 0.08...</td>\n",
       "      <td>[democratic, joe, biden, seals, presidential, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>481</td>\n",
       "      <td>51</td>\n",
       "      <td>[(accuses, 0.14427005906294704), (giuliani, 0....</td>\n",
       "      <td>[accuses, giuliani, disinformation, lawyer, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>208</td>\n",
       "      <td>51</td>\n",
       "      <td>[(dejoy, 0.16734225254893453), (louis, 0.13729...</td>\n",
       "      <td>[dejoy, louis, reimbursed, postmaster, donate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>319</td>\n",
       "      <td>50</td>\n",
       "      <td>[(trump, 0.051583369312506726), (votes, 0.0384...</td>\n",
       "      <td>[trump, votes, vote, republican, donald, repub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic    Size                                    topic top words  \\\n",
       "0       -1  347704  [(trump, 0.021263067193352816), (president, 0....   \n",
       "362    361    4247  [(twitter, 0.09277363693910848), (facebook, 0....   \n",
       "458    457    3446  [(good, 0.07022461672120524), (great, 0.042902...   \n",
       "139    138    3154  [(https, 0.1580439995285021), (com, 0.15198126...   \n",
       "170    169    2338  [(russian, 0.10859609065953478), (russia, 0.09...   \n",
       "..     ...     ...                                                ...   \n",
       "121    120      51  [(game, 0.2633899598384372), (star, 0.24340667...   \n",
       "152    151      51  [(democratic, 0.12098058076373801), (joe, 0.08...   \n",
       "482    481      51  [(accuses, 0.14427005906294704), (giuliani, 0....   \n",
       "209    208      51  [(dejoy, 0.16734225254893453), (louis, 0.13729...   \n",
       "320    319      50  [(trump, 0.051583369312506726), (votes, 0.0384...   \n",
       "\n",
       "                                                 words  \n",
       "0    [trump, president, biden, election, said, joe,...  \n",
       "362  [twitter, facebook, social, media, account, tr...  \n",
       "458  [good, great, right, think, know, time, love, ...  \n",
       "139  [https, com, www, fbclid, 2020, msn, politics,...  \n",
       "170  [russian, russia, intelligence, putin, vladimi...  \n",
       "..                                                 ...  \n",
       "121  [game, star, baseball, league, atlanta, major,...  \n",
       "152  [democratic, joe, biden, seals, presidential, ...  \n",
       "482  [accuses, giuliani, disinformation, lawyer, ca...  \n",
       "209  [dejoy, louis, reimbursed, postmaster, donate,...  \n",
       "320  [trump, votes, vote, republican, donald, repub...  \n",
       "\n",
       "[509 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sizes['topic top words']=topic_sizes['Topic'].map(top_n_words)\n",
    "\n",
    "def word_extract(x):\n",
    "    if type(x)!= float:\n",
    "        z=[tup[0] for tup in x]\n",
    "    else: z=1\n",
    "    return z\n",
    "\n",
    "topic_sizes['words']=topic_sizes['topic top words'].apply(lambda x:word_extract(x))\n",
    "topic_sizes=topic_sizes[topic_sizes['words']!=1]\n",
    "topic_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c27680e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Size</th>\n",
       "      <th>topic top words</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>58</td>\n",
       "      <td>258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>56</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>59</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>48</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Size topic top words words\n",
       "56     55   400             NaN     1\n",
       "1       0   382             NaN     1\n",
       "59     58   258             NaN     1\n",
       "57     56   104             NaN     1\n",
       "60     59    87             NaN     1\n",
       "49     48    82             NaN     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sizes[topic_sizes['words']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0ca54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sizes=topic_sizes[topic_sizes['words']!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6401c114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Size</th>\n",
       "      <th>topic top words</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>347704</td>\n",
       "      <td>[(trump, 0.021263067193352816), (president, 0....</td>\n",
       "      <td>[trump, president, biden, election, said, joe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>361</td>\n",
       "      <td>4247</td>\n",
       "      <td>[(twitter, 0.09277363693910848), (facebook, 0....</td>\n",
       "      <td>[twitter, facebook, social, media, account, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>457</td>\n",
       "      <td>3446</td>\n",
       "      <td>[(good, 0.07022461672120524), (great, 0.042902...</td>\n",
       "      <td>[good, great, right, think, know, time, love, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>138</td>\n",
       "      <td>3154</td>\n",
       "      <td>[(https, 0.1580439995285021), (com, 0.15198126...</td>\n",
       "      <td>[https, com, www, fbclid, 2020, msn, politics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>169</td>\n",
       "      <td>2338</td>\n",
       "      <td>[(russian, 0.10859609065953478), (russia, 0.09...</td>\n",
       "      <td>[russian, russia, intelligence, putin, vladimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>120</td>\n",
       "      <td>51</td>\n",
       "      <td>[(game, 0.2633899598384372), (star, 0.24340667...</td>\n",
       "      <td>[game, star, baseball, league, atlanta, major,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>151</td>\n",
       "      <td>51</td>\n",
       "      <td>[(democratic, 0.12098058076373801), (joe, 0.08...</td>\n",
       "      <td>[democratic, joe, biden, seals, presidential, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>481</td>\n",
       "      <td>51</td>\n",
       "      <td>[(accuses, 0.14427005906294704), (giuliani, 0....</td>\n",
       "      <td>[accuses, giuliani, disinformation, lawyer, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>208</td>\n",
       "      <td>51</td>\n",
       "      <td>[(dejoy, 0.16734225254893453), (louis, 0.13729...</td>\n",
       "      <td>[dejoy, louis, reimbursed, postmaster, donate,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>319</td>\n",
       "      <td>50</td>\n",
       "      <td>[(trump, 0.051583369312506726), (votes, 0.0384...</td>\n",
       "      <td>[trump, votes, vote, republican, donald, repub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic    Size                                    topic top words  \\\n",
       "0       -1  347704  [(trump, 0.021263067193352816), (president, 0....   \n",
       "362    361    4247  [(twitter, 0.09277363693910848), (facebook, 0....   \n",
       "458    457    3446  [(good, 0.07022461672120524), (great, 0.042902...   \n",
       "139    138    3154  [(https, 0.1580439995285021), (com, 0.15198126...   \n",
       "170    169    2338  [(russian, 0.10859609065953478), (russia, 0.09...   \n",
       "..     ...     ...                                                ...   \n",
       "121    120      51  [(game, 0.2633899598384372), (star, 0.24340667...   \n",
       "152    151      51  [(democratic, 0.12098058076373801), (joe, 0.08...   \n",
       "482    481      51  [(accuses, 0.14427005906294704), (giuliani, 0....   \n",
       "209    208      51  [(dejoy, 0.16734225254893453), (louis, 0.13729...   \n",
       "320    319      50  [(trump, 0.051583369312506726), (votes, 0.0384...   \n",
       "\n",
       "                                                 words  \n",
       "0    [trump, president, biden, election, said, joe,...  \n",
       "362  [twitter, facebook, social, media, account, tr...  \n",
       "458  [good, great, right, think, know, time, love, ...  \n",
       "139  [https, com, www, fbclid, 2020, msn, politics,...  \n",
       "170  [russian, russia, intelligence, putin, vladimi...  \n",
       "..                                                 ...  \n",
       "121  [game, star, baseball, league, atlanta, major,...  \n",
       "152  [democratic, joe, biden, seals, presidential, ...  \n",
       "482  [accuses, giuliani, disinformation, lawyer, ca...  \n",
       "209  [dejoy, louis, reimbursed, postmaster, donate,...  \n",
       "320  [trump, votes, vote, republican, donald, repub...  \n",
       "\n",
       "[503 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sizes.to_csv('topic_sizes.csv')\n",
    "topic_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d37a0536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topic_sizes['Topic'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb74aeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dml', 0.9937668157626008),\n",
       " ('offers', 0.8782998848366768),\n",
       " ('app', 0.8664674442343197),\n",
       " ('news', 0.7845449377223067),\n",
       " ('reporting', 0.7579552627671509),\n",
       " ('best', 0.7245379919728183),\n",
       " ('ùòÜùóºùòÇùóø', 0.0),\n",
       " ('eratic', 0.0),\n",
       " ('erased', 0.0),\n",
       " ('eraser', 0.0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words[5][:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
