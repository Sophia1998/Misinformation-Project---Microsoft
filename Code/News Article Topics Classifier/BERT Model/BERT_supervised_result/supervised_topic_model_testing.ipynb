{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T3gOulnunU6r"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_pretrained_bert\n",
    "!pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBzMiCyynkMm",
    "outputId": "bbc3da85-b465-46d6-8e32-acee8a559e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.sh\n",
    "\n",
    "git clone https://github.com/NVIDIA/apex\n",
    "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yYK8_62nnc3"
   },
   "outputs": [],
   "source": [
    "!sh setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNm5K65WnhY2"
   },
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "from torch import Tensor\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from fastai.text import Tokenizer, Vocab\n",
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import pdb\n",
    "from tqdm import tqdm, trange\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "#import apex\n",
    "from sklearn.model_selection import train_test_split\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from pytorch_pretrained_bert.optimization import BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quwB4SgUHCLs"
   },
   "outputs": [],
   "source": [
    "!pip install apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfqjVAqFntdR"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7db686Wnvck"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHnL7hVUnxJc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('drive')\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seKtSmKynzhl"
   },
   "outputs": [],
   "source": [
    "DATA_PATH=Path('./data')\n",
    "DATA_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "PATH=Path('./tmp')\n",
    "PATH.mkdir(exist_ok=True)\n",
    "\n",
    "CLAS_DATA_PATH=PATH/'class'\n",
    "CLAS_DATA_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "model_state_dict = None\n",
    "\n",
    "BERT_PRETRAINED_PATH = Path('./uncased_L-12_H-768_A-12/')\n",
    "\n",
    "PYTORCH_PRETRAINED_BERT_CACHE = BERT_PRETRAINED_PATH/'cache/'\n",
    "PYTORCH_PRETRAINED_BERT_CACHE.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7gEgl3Bn1an"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"train_size\": 86519,\n",
    "    \"val_size\": 21630,\n",
    "    \"full_data_dir\": DATA_PATH,\n",
    "    \"data_dir\": PATH,\n",
    "    \"task_name\": \"topic_multilabel\",\n",
    "    \"no_cuda\": False,\n",
    "    \"bert_model\": BERT_PRETRAINED_PATH,\n",
    "    \"output_dir\": CLAS_DATA_PATH/'output',\n",
    "    \"max_seq_length\": 128,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"do_lower_case\": True,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"eval_batch_size\": 1,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_train_epochs\": 4.0,\n",
    "    \"warmup_proportion\": 0.1,\n",
    "    \"no_cuda\": False,\n",
    "    \"local_rank\": -1,\n",
    "    \"seed\": 42,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"optimize_on_cpu\": False,\n",
    "    \"fp16\": False,\n",
    "    \"loss_scale\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hJCG5gtoVx2"
   },
   "outputs": [],
   "source": [
    "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels=2):\n",
    "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits\n",
    "        \n",
    "    def freeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_bert_encoder(self):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1m--scppyhl"
   },
   "source": [
    "## Data representation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMUSCqIjpvuF"
   },
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "\n",
    "        Args:\n",
    "            guid: Unique id for the example.\n",
    "            text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "            Only must be specified for sequence pair tasks.\n",
    "            labels: (Optional) [string]. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.labels = labels\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_ids = label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pi3G3yuPp1Dy"
   },
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError() \n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yb5Kr07Jp5jw"
   },
   "outputs": [],
   "source": [
    "class MultiLabelTextProcessor(DataProcessor):\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = None\n",
    "    \n",
    "    \n",
    "    def get_train_examples(self, data_dir, size=-1):\n",
    "        filename = 'fulltext_cleaned_train.csv'\n",
    "        \n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
    "        if size == -1:\n",
    "            data_df = pd.read_csv(os.path.join(data_dir, filename), engine = 'python')\n",
    "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
    "            return self._create_examples(data_df, \"train\")\n",
    "        else:\n",
    "            data_df = pd.read_csv(os.path.join(data_dir, filename), engine = 'python')\n",
    "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
    "            return self._create_examples(data_df.sample(size), \"train\")\n",
    "        \n",
    "    def get_dev_examples(self, data_dir, size=-1):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        filename = 'fulltext_cleaned_test.csv'\n",
    "\n",
    "        if size == -1:\n",
    "            data_df = pd.read_csv(os.path.join(data_dir, filename), error_bad_lines = False, engine = \"python\")\n",
    "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
    "            return self._create_examples(data_df, \"dev\")\n",
    "        else:\n",
    "            data_df = pd.read_csv(os.path.join(data_dir, filename), error_bad_lines = False, engine = \"python\")\n",
    "#             data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
    "            return self._create_examples(data_df.sample(size), \"dev\")\n",
    "    \n",
    "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
    "        data_df = pd.read_csv(os.path.join(data_dir, data_file_name))\n",
    "#         data_df['comment_text'] = data_df['comment_text'].apply(cleanHtml)\n",
    "        if size == -1:\n",
    "            return self._create_examples(data_df, \"test\", labels_available=False)\n",
    "        else:\n",
    "            return self._create_examples(data_df.sample(size), \"test\", labels_available=False)\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        if self.labels == None:\n",
    "            self.labels = list(pd.read_csv(os.path.join(self.data_dir, \"classes.txt\"),header=None)[0].values)\n",
    "        return self.labels\n",
    "\n",
    "    def _create_examples(self, df, set_type, labels_available=True):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, row) in enumerate(df.values):\n",
    "            guid = row[0]\n",
    "            text_a = row[1]\n",
    "            if labels_available:\n",
    "                labels = row[2:]\n",
    "            else:\n",
    "                labels = []\n",
    "            examples.append(\n",
    "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
    "        return examples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eIFFRIrp8ph"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    label_map = {label : i for i, label in enumerate(label_list)}\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        tokens_b = None\n",
    "        if example.text_b:\n",
    "            tokens_b = tokenizer.tokenize(example.text_b)\n",
    "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "        else:\n",
    "            if len(tokens_a) > max_seq_length - 2:\n",
    "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
    "\n",
    "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "        segment_ids = [0] * len(tokens)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens += tokens_b + [\"[SEP]\"]\n",
    "            segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        \n",
    "        labels_ids = []\n",
    "        for label in example.labels:\n",
    "            labels_ids.append(float(label))\n",
    "        \n",
    "        #label_id = label_map[example.labels[0]]\n",
    "        \n",
    "        if ex_index < 0:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % (example.guid))\n",
    "            logger.info(\"tokens: %s\" % \" \".join(\n",
    "                    [str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\n",
    "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label: %s (id = %s)\" % (example.labels, label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_ids=labels_ids))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-PW_HTBp-fx"
   },
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SA0AsCqjpfVr"
   },
   "source": [
    "#*Metric functions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dUs6CE8pdNj"
   },
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    outputs = np.argmax(out, axis=1)\n",
    "    return np.sum(outputs == labels)\n",
    "\n",
    "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
    "\n",
    "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = (y_pred>thresh).float()\n",
    "    y_true = y_true.float()\n",
    "    TP = (y_pred*y_true).sum(dim=1)\n",
    "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
    "    rec = TP/(y_true.sum(dim=1)+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sihosVLzF_xC"
   },
   "outputs": [],
   "source": [
    "def precision_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred_bool = y_pred>thresh\n",
    "    y_pred_bool_p = y_pred_bool[y_pred_bool]\n",
    "    y_true = y_true[y_pred_bool]\n",
    "    if len(y_true) == 0: return 0,0\n",
    "    result = np.mean((y_pred_bool_p==y_true.byte()).float().cpu().numpy(), axis=0).sum()\n",
    "    return result, len(y_pred_bool_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RD7B1tNtYps4"
   },
   "outputs": [],
   "source": [
    "def recall_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
    "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred_bool = y_pred>thresh\n",
    "    y_pred_bool_p = y_pred_bool[y_true.byte()]\n",
    "    y_true = y_true[y_true.byte()].byte()\n",
    "    if len(y_true) == 0: return 0,0\n",
    "    result = np.mean((y_pred_bool_p==y_true.byte()).float().cpu().numpy(), axis=0).sum()\n",
    "    return result, len(y_pred_bool_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roj2hVUDoeZc"
   },
   "source": [
    "# Start Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbnTyqwIpVPL"
   },
   "outputs": [],
   "source": [
    "processors = {\n",
    "    \"topic_multilabel\": MultiLabelTextProcessor\n",
    "}\n",
    "\n",
    "# Setup GPU parameters\n",
    "\n",
    "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "#     n_gpu = 1\n",
    "else:\n",
    "    torch.cuda.set_device(args['local_rank'])\n",
    "    device = torch.device(\"cuda\", args['local_rank'])\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
    "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CaCNaQJ5Fe7"
   },
   "outputs": [],
   "source": [
    "task_name = args['task_name'].lower()\n",
    "\n",
    "if task_name not in processors:\n",
    "    raise ValueError(\"Task not found: %s\" % (task_name))\n",
    "\n",
    "processor = processors[task_name](args['data_dir'])\n",
    "label_list = processor.get_labels()\n",
    "num_labels = len(label_list)\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INlmMx72dg9E"
   },
   "source": [
    "## Read in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5X3VGOtn9gT"
   },
   "outputs": [],
   "source": [
    "output_model_file = os.path.join(PYTORCH_PRETRAINED_BERT_CACHE, \"finetuned_pytorch_model.bin\")\n",
    "model_state_dict = torch.load(output_model_file)\n",
    "model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Bukdam5r_uG"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args['bert_model'], do_lower_case=args['do_lower_case'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJw7hqwV44tG"
   },
   "outputs": [],
   "source": [
    "# Eval Fn\n",
    "eval_examples = processor.get_dev_examples(args['data_dir'], size=args['val_size'])\n",
    "args['output_dir'].mkdir(exist_ok=True)\n",
    "\n",
    "eval_features = convert_examples_to_features(\n",
    "    eval_examples, label_list, args['max_seq_length'], tokenizer)\n",
    "logger.info(\"***** Running evaluation *****\")\n",
    "logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "all_label_ids = torch.tensor([f.label_ids for f in eval_features], dtype=torch.float)\n",
    "eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "# Run prediction for full data\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhab7vW-bAK7",
    "outputId": "5ba41036-5de6-4690-ce41-6ad9895ecf71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "all_logits = None\n",
    "all_labels = None\n",
    "model.eval()\n",
    "eval_loss, eval_accuracy, eval_recall, eval_precision = 0, 0, 0, 0\n",
    "nb_eval_steps, nb_eval_examples, tp_fp, tp_fn  = 0, 0, 0, 0\n",
    "for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
    "    input_ids = input_ids.to(device)\n",
    "    input_mask = input_mask.to(device)\n",
    "    segment_ids = segment_ids.to(device)\n",
    "    label_ids = label_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "        logits = model(input_ids, segment_ids, input_mask)\n",
    "\n",
    "    tmp_eval_accuracy = accuracy_thresh(logits, label_ids)\n",
    "    tmp_eval_recall, tmp_tp_fn = recall_thresh(logits, label_ids)\n",
    "    tmp_eval_precision, tmp_tp_fp = precision_thresh(logits, label_ids)\n",
    "\n",
    "    if all_logits is None:\n",
    "        all_logits = logits.detach().cpu().numpy()\n",
    "    else:\n",
    "        all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
    "        \n",
    "    if all_labels is None:\n",
    "        all_labels = label_ids.detach().cpu().numpy()\n",
    "    else:    \n",
    "        all_labels = np.concatenate((all_labels, label_ids.detach().cpu().numpy()), axis=0)\n",
    "    \n",
    "\n",
    "    eval_loss += tmp_eval_loss.mean().item()\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    eval_recall += tmp_eval_recall\n",
    "    eval_precision += tmp_eval_precision\n",
    "    #print(eval_precision)\n",
    "    tp_fp += tmp_tp_fp\n",
    "    tp_fn += tmp_tp_fn\n",
    "    nb_eval_examples += input_ids.size(0)\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "eval_loss = eval_loss / nb_eval_steps\n",
    "eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "eval_recall = eval_recall / tp_fn\n",
    "eval_precision = eval_precision / tp_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tmL3meujbGx-",
    "outputId": "4c538df5-04a0-4465-d050-be2c81b53888"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2022 04:15:29 - INFO - __main__ -   ***** Eval results *****\n",
      "03/05/2022 04:15:29 - INFO - __main__ -     accuracy = {0: 0.9900601017105871, 1: 0.9924641701340731, 2: 0.989828941285252, 3: 0.9664355062413315, 4: 0.9611650485436893, 5: 0.9691631992602866, 6: 0.9807212205270458, 7: 0.986130374479889, 8: 0.997595931576514, 9: 0.7901063337956542, 10: 0.9729542302357836, 11: 0.9226999537679149, 12: 0.9948220064724919, 13: 0.9968562182154416, 14: 0.8809061488673139, 15: 0.9389736477115118}\n",
      "03/05/2022 04:15:29 - INFO - __main__ -     eval_accuracy = 0.9581801895515488\n",
      "03/05/2022 04:15:29 - INFO - __main__ -     eval_loss = 0.08919032775686939\n",
      "03/05/2022 04:15:29 - INFO - __main__ -     eval_precision = 0.7027991052536122\n",
      "03/05/2022 04:15:29 - INFO - __main__ -     eval_recall = 0.5481691978011739\n",
      "03/05/2022 04:15:29 - INFO - __main__ -     precision = {0: 0.7109004739336493, 1: 0.39285714285714285, 2: 0.5238095238095238, 3: 0.5371900826446281, 4: 0.5055762081784386, 5: 0.5976331360946746, 6: 0.6932153392330384, 7: 0.46017699115044247, 8: 0.6666666666666666, 9: 0.7638611886717191, 10: 0.6751592356687898, 11: 0.7006432459178624, 12: 0.7209302325581395, 13: 0.5, 14: 0.6961451247165533, 15: 0.6555023923444976}\n",
      "03/05/2022 04:15:29 - INFO - __main__ -     recall = {0: 0.4934210526315789, 1: 0.07006369426751592, 2: 0.24444444444444444, 3: 0.08843537414965986, 4: 0.16132858837485173, 5: 0.5056320400500626, 6: 0.42883211678832117, 7: 0.17869415807560138, 8: 0.29508196721311475, 9: 0.6751674697379245, 10: 0.424, 11: 0.5702778896496175, 12: 0.2366412213740458, 13: 0.3382352941176471, 14: 0.5674676524953789, 15: 0.540281690140845}\n",
      "03/05/2022 04:15:29 - INFO - __main__ -     roc_auc = {0: 0.9772719981046116, 1: 0.9464273160695658, 2: 0.980740014015417, 3: 0.9668001165529624, 4: 0.9630171950817195, 5: 0.9572225230652617, 6: 0.9638058671838915, 7: 0.9508393308542882, 8: 0.9708012942071538, 9: 0.8930023827239362, 10: 0.9311208812260536, 11: 0.9424806393824273, 12: 0.9580289372592866, 13: 0.9797079693578573, 14: 0.936596571915641, 15: 0.9559209621871243, 'micro': 0.9727227317529239}\n"
     ]
    }
   ],
   "source": [
    "#     ROC-AUC calcualation\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "recall_dict = dict()\n",
    "precision_dict = dict()\n",
    "accuracy_dict = dict()\n",
    "\n",
    "\n",
    "for i in range(num_labels):\n",
    "    fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_logits[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    pred_bool = 1/(1 + np.exp(-all_logits[:, i]))\n",
    "    recall_dict[i] = recall_score(all_labels[:, i], pred_bool>0.5)\n",
    "    precision_dict[i] = precision_score(all_labels[:, i], pred_bool>0.5)\n",
    "    accuracy_dict[i] = accuracy_score(all_labels[:, i], pred_bool>0.5)\n",
    "\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_logits.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "result = {'eval_loss': eval_loss,\n",
    "          'eval_accuracy': eval_accuracy,\n",
    "          'eval_recall' : eval_recall,\n",
    "          'eval_precision' : eval_precision,\n",
    "#               'loss': tr_loss/nb_tr_steps,\n",
    "          'roc_auc': roc_auc,\n",
    "          'accuracy': accuracy_dict,\n",
    "          'precision': precision_dict,\n",
    "          'recall': recall_dict}\n",
    "\n",
    "output_eval_file = os.path.join(args['output_dir'], \"eval_results.txt\")\n",
    "with open(output_eval_file, \"w\") as writer:\n",
    "    logger.info(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "#             writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9m84HitDRr1",
    "outputId": "f8cb703a-0977-42fa-dc3f-6f055ccc049e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9727227317529239"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels_re = all_labels.reshape(-1)\n",
    "all_logits_re = all_logits.reshape(-1)\n",
    "fpr_all, tpr_all, _ = roc_curve(all_labels_re, all_logits_re)\n",
    "roc_auc_all = auc(fpr_all, tpr_all)\n",
    "roc_auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "5PZbsbFUDu7Z",
    "outputId": "d128633c-6954-4021-9ef8-80fa5f0b9e7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'TPR')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr_all, tpr_all)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4QbZukado1n"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d_3n3irqq5g"
   },
   "outputs": [],
   "source": [
    "def predict(model, path, test_filename='fulltext_cleaned_test.csv', label_ava=True):\n",
    "    predict_processor = MultiLabelTextProcessor(path)\n",
    "    test_examples = predict_processor.get_test_examples(path, test_filename, size=-1)\n",
    "    \n",
    "    # Hold input data for returning it \n",
    "    input_data = [{ 'id': input_example.guid, 'comment_text': input_example.text_a } for input_example in test_examples]\n",
    "\n",
    "    test_features = convert_examples_to_features(\n",
    "        test_examples, label_list, args['max_seq_length'], tokenizer)\n",
    "    \n",
    "    logger.info(\"***** Running prediction *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(test_examples))\n",
    "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
    "    \n",
    "    all_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
    "\n",
    "    test_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "    \n",
    "    # Run prediction for full data\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=args['eval_batch_size'])\n",
    "    \n",
    "    all_logits = None\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for step, batch in enumerate(tqdm(test_dataloader, desc=\"Prediction Iteration\")):\n",
    "        input_ids, input_mask, segment_ids = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, segment_ids, input_mask)\n",
    "            logits = logits.sigmoid()\n",
    "\n",
    "        if all_logits is None:\n",
    "            all_logits = logits.detach().cpu().numpy()\n",
    "        else:\n",
    "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
    "            \n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    return pd.merge(pd.DataFrame(input_data), pd.DataFrame(all_logits, columns=label_list), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Cj_KRdHEHSe"
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SHPscyFPD6OS",
    "outputId": "84e72631-0532-4630-f4bf-74101a6c06cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2022 04:20:41 - INFO - __main__ -   ***** Running prediction *****\n",
      "03/05/2022 04:20:41 - INFO - __main__ -     Num examples = 21630\n",
      "03/05/2022 04:20:41 - INFO - __main__ -     Batch size = 1\n",
      "Prediction Iteration: 100%|██████████| 21630/21630 [04:54<00:00, 73.51it/s]\n"
     ]
    }
   ],
   "source": [
    "result = predict(model, DATA_PATH)\n",
    "bool_dic = {'id': result.id.values, 'comment_text': result.comment_text.values}\n",
    "for l in label_list:\n",
    "  curr = result[l].values\n",
    "  curr_l = [int(x>0.5) for x in curr]\n",
    "  bool_dic[l] = curr_l\n",
    "result_bool = pd.DataFrame(data=bool_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2oBHVTqD-oh"
   },
   "outputs": [],
   "source": [
    "result_bool.to_csv(DATA_PATH/'test_data_result.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQuU6e4KrtWi",
    "outputId": "5ae20b01-b85f-4d00-ac94-e3440ea0df37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2022 04:25:58 - INFO - __main__ -   ***** Running prediction *****\n",
      "03/05/2022 04:25:58 - INFO - __main__ -     Num examples = 1453\n",
      "03/05/2022 04:25:58 - INFO - __main__ -     Batch size = 1\n",
      "Prediction Iteration: 100%|██████████| 1453/1453 [00:19<00:00, 74.08it/s]\n"
     ]
    }
   ],
   "source": [
    "result = predict(model, DATA_PATH, test_filename='inference_result_text.csv')\n",
    "bool_dic = {'id': result.id.values, 'comment_text': result.comment_text.values}\n",
    "for l in label_list:\n",
    "  curr = result[l].values\n",
    "  curr_l = [int(x>0.5) for x in curr]\n",
    "  bool_dic[l] = curr_l\n",
    "result_bool = pd.DataFrame(data=bool_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGbgXhj2sJP0"
   },
   "outputs": [],
   "source": [
    "result_bool.to_csv(DATA_PATH/'inference_data_result.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cYAH-mS5WXbP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "supervised_topic_model_testing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
